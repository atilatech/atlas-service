{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNw+pbh5vbldTaAEnESTTPK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atilatech/atlas-service/blob/master/notebooks/deploy_whisper_huggingface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWcH5qau6xW5"
      },
      "outputs": [],
      "source": [
        "!pip install transformers pytube\n",
        "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q\n",
        "!apt install ffmpeg # https://stackoverflow.com/questions/51856340/how-to-install-package-ffmpeg-in-google-colab\n",
        "\n",
        "# optional install pytorch so you can use a gpu for faster transcription\n",
        "# command below is for Linux. See instructions for mac and windows: https://pytorch.org/get-started/locally/\n",
        "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pojSykoTUB6I",
        "outputId": "655c4cd2-3642-46ea-8bb6-bc4b5af24c30"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.11-0ubuntu0.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0+cu116)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import pytube as pt\n",
        "import whisper\n",
        "\n",
        "MODEL_NAME = \"tiny.en\" #this always needs to stay in line 8 :D sorry for the hackiness\n",
        "lang = \"en\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"using device: \", device)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f'whisper will use: {device}')\n",
        "\n",
        "whisper_model = whisper.load_model(MODEL_NAME).to(device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqUPzzR5-HwK",
        "outputId": "642ea275-d645-4d2b-a130-7b39d19fb2bf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device:  cpu\n",
            "whisper will use: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "def yt_transcribe(yt_url):\n",
        "\n",
        "\n",
        "    decode_options = {\n",
        "        # Set language to None to support multilingual, \n",
        "        # but it will take longer to process while it detects the language.\n",
        "        # Realized this by running in verbose mode and seeing how much time\n",
        "        # was spent on the decoding language step\n",
        "        \"language\":\"en\",\n",
        "        \"verbose\": True\n",
        "      }\n",
        "    yt = pt.YouTube(yt_url)\n",
        "    stream = yt.streams.filter(only_audio=True)[0]\n",
        "    path_to_audio = f\"{yt.video_id}.mp3\"\n",
        "    stream.download(filename=path_to_audio)\n",
        "\n",
        "    # with open(path_to_audio, \"rb\") as i:\n",
        "    #     audio_binary = i.read()\n",
        "\n",
        "    t0 = time.time()\n",
        "    transcript = whisper_model.transcribe(path_to_audio, **decode_options)\n",
        "    t1 = time.time()\n",
        "    \n",
        "    total = t1-t0\n",
        "    print(f'Finished transcription in {total} seconds')\n",
        "    return transcript"
      ],
      "metadata": {
        "id": "ij6pw1QURyja"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_url=\"https://www.youtube.com/watch?v=aNxigRg1yEQ\"\n",
        "transcription = yt_transcribe(video_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDG_n3_GPqXb",
        "outputId": "b2c7b70d-2139-46ca-c549-130505f05c8f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:03.920]  Because if I just think, well tomorrow I'm just gonna coast and eat Twinkies and watch TV.\n",
            "[00:03.920 --> 00:06.400]  Oh, hello, sadness, my old friend.\n",
            "[00:06.400 --> 00:07.600]  Hello, depression.\n",
            "[00:07.600 --> 00:09.920]  Because when you're not doing anything you feel like shit.\n",
            "[00:09.920 --> 00:12.000]  And that's just a part of being a human being.\n",
            "[00:12.000 --> 00:14.800]  And we can pretend that we're something other than what we really are.\n",
            "[00:14.800 --> 00:18.800]  And we can pretend, nah, me man, I'm just cool, just chilling, doing nothing.\n",
            "[00:18.800 --> 00:20.800]  Bullshit. You're a fucking human.\n",
            "[00:20.800 --> 00:26.480]  You're a human being. You evolve from the fucking hundreds of thousands of years of hunters and gatherers\n",
            "[00:26.480 --> 00:31.440]  and people who are struggling. Human reward systems are carved deeply into your DNA.\n",
            "[00:31.440 --> 00:36.560]  And if you don't respect that, if you don't respect the mechanism of happiness and fulfillment\n",
            "[00:36.560 --> 00:40.080]  and what you really need to do in order to feel satisfied in life,\n",
            "[00:40.880 --> 00:48.000]  comradery, love, family, friendship, struggle, testing yourself, learning,\n",
            "[00:48.000 --> 00:58.000]  all those things are imperative. They're all a giant part of being a person.\n",
            "Finished transcription in 10.77533769607544 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcription"
      ],
      "metadata": {
        "id": "E3-TZYlGSd7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a custom handler"
      ],
      "metadata": {
        "id": "kW7gBEJpgsDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import  Dict\n",
        "from transformers.pipelines.audio_utils import ffmpeg_read\n",
        "import whisper\n",
        "import torch\n",
        "import pytube\n",
        "import time\n",
        "\n",
        "\n",
        "class EndpointHandler():\n",
        "    def __init__(self, path=\"\"):\n",
        "        # load the model\n",
        "        MODEL_NAME = \"tiny.en\"\n",
        "        \n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f'whisper will use: {device}')\n",
        "        \n",
        "        t0 = time.time()\n",
        "        self.model = whisper.load_model(MODEL_NAME).to(device)\n",
        "        t1 = time.time()\n",
        "        \n",
        "        total = t1-t0\n",
        "        print(f'Finished loading model in {total} seconds')\n",
        "\n",
        "\n",
        "    def __call__(self, data: Dict[str, bytes]) -> Dict[str, str]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data (:obj:):\n",
        "                includes the URL to video for transcription\n",
        "        Return:\n",
        "            A :obj:`dict`:. transcribed dict\n",
        "        \"\"\"\n",
        "        # process input\n",
        "        print('data', data)\n",
        "        video_url = data.pop(\"inputs\", data)\n",
        "        decode_options = {\n",
        "            # Set language to None to support multilingual, \n",
        "            # but it will take longer to process while it detects the language.\n",
        "            # Realized this by running in verbose mode and seeing how much time\n",
        "            # was spent on the decoding language step\n",
        "            \"language\":\"en\",\n",
        "            \"verbose\": True\n",
        "        }\n",
        "        yt = pytube.YouTube(video_url)\n",
        "        stream = yt.streams.filter(only_audio=True)[0]\n",
        "        path_to_audio = f\"{yt.video_id}.mp3\"\n",
        "        stream.download(filename=path_to_audio)\n",
        "        t0 = time.time()\n",
        "        transcript = self.model.transcribe(path_to_audio, **decode_options)\n",
        "        t1 = time.time()\n",
        "        \n",
        "        total = t1-t0\n",
        "        print(f'Finished transcription in {total} seconds')\n",
        "        \n",
        "\n",
        "        # postprocess the prediction\n",
        "        return {\"transcript\": transcript}\n"
      ],
      "metadata": {
        "id": "JAc8Yxdggumo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Handler\n",
        "\n",
        "my_handler = EndpointHandler(path=\".\")\n",
        "\n",
        "# prepare sample payload\n",
        "payload = {\"inputs\": \"https://www.youtube.com/watch?v=aNxigRg1yEQ\"}\n",
        "holiday_payload = {\"inputs\": \"Today is a though day\", \"date\": \"2022-07-04\"}\n",
        "\n",
        "# test the handler\n",
        "payload_pred=my_handler(payload)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlPfk9CDg6UP",
        "outputId": "6da37f6c-5e1c-4e11-dd4c-a18ff42cc348"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "whisper will use: cpu\n",
            "Finished loading model in 0.3354830741882324 seconds\n",
            "data {'inputs': 'https://www.youtube.com/watch?v=aNxigRg1yEQ'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:03.920]  Because if I just think, well tomorrow I'm just gonna coast and eat Twinkies and watch TV.\n",
            "[00:03.920 --> 00:06.400]  Oh, hello, sadness, my old friend.\n",
            "[00:06.400 --> 00:07.600]  Hello, depression.\n",
            "[00:07.600 --> 00:09.920]  Because when you're not doing anything you feel like shit.\n",
            "[00:09.920 --> 00:12.000]  And that's just a part of being a human being.\n",
            "[00:12.000 --> 00:14.800]  And we can pretend that we're something other than what we really are.\n",
            "[00:14.800 --> 00:18.800]  And we can pretend, nah, me man, I'm just cool, just chilling, doing nothing.\n",
            "[00:18.800 --> 00:20.800]  Bullshit. You're a fucking human.\n",
            "[00:20.800 --> 00:26.480]  You're a human being. You evolve from the fucking hundreds of thousands of years of hunters and gatherers\n",
            "[00:26.480 --> 00:31.440]  and people who are struggling. Human reward systems are carved deeply into your DNA.\n",
            "[00:31.440 --> 00:36.560]  And if you don't respect that, if you don't respect the mechanism of happiness and fulfillment\n",
            "[00:36.560 --> 00:40.080]  and what you really need to do in order to feel satisfied in life,\n",
            "[00:40.880 --> 00:48.000]  comradery, love, family, friendship, struggle, testing yourself, learning,\n",
            "[00:48.000 --> 00:58.000]  all those things are imperative. They're all a giant part of being a person.\n",
            "Finished transcription in 10.760913848876953 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "payload_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQlIqL13hVx6",
        "outputId": "a0a0aa22-ea31-4b24-f912-37bdb504cde3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'transcript': {'text': \" Because if I just think, well tomorrow I'm just gonna coast and eat Twinkies and watch TV. Oh, hello, sadness, my old friend. Hello, depression. Because when you're not doing anything you feel like shit. And that's just a part of being a human being. And we can pretend that we're something other than what we really are. And we can pretend, nah, me man, I'm just cool, just chilling, doing nothing. Bullshit. You're a fucking human. You're a human being. You evolve from the fucking hundreds of thousands of years of hunters and gatherers and people who are struggling. Human reward systems are carved deeply into your DNA. And if you don't respect that, if you don't respect the mechanism of happiness and fulfillment and what you really need to do in order to feel satisfied in life, comradery, love, family, friendship, struggle, testing yourself, learning, all those things are imperative. They're all a giant part of being a person.\",\n",
              "  'segments': [{'id': 0,\n",
              "    'seek': 0,\n",
              "    'start': 0.0,\n",
              "    'end': 3.92,\n",
              "    'text': \" Because if I just think, well tomorrow I'm just gonna coast and eat Twinkies and watch TV.\",\n",
              "    'tokens': [4362,\n",
              "     611,\n",
              "     314,\n",
              "     655,\n",
              "     892,\n",
              "     11,\n",
              "     880,\n",
              "     9439,\n",
              "     314,\n",
              "     1101,\n",
              "     655,\n",
              "     8066,\n",
              "     7051,\n",
              "     290,\n",
              "     4483,\n",
              "     1815,\n",
              "     676,\n",
              "     444,\n",
              "     290,\n",
              "     2342,\n",
              "     3195,\n",
              "     13],\n",
              "    'temperature': 0.0,\n",
              "    'avg_logprob': -0.25675727844238283,\n",
              "    'compression_ratio': 1.808724832214765,\n",
              "    'no_speech_prob': 0.08218304067850113},\n",
              "   {'id': 1,\n",
              "    'seek': 0,\n",
              "    'start': 3.92,\n",
              "    'end': 6.4,\n",
              "    'text': ' Oh, hello, sadness, my old friend.',\n",
              "    'tokens': [3966, 11, 23748, 11, 6507, 1108, 11, 616, 1468, 1545, 13],\n",
              "    'temperature': 0.0,\n",
              "    'avg_logprob': -0.25675727844238283,\n",
              "    'compression_ratio': 1.808724832214765,\n",
              "    'no_speech_prob': 0.08218304067850113},\n",
              "   {'id': 2,\n",
              "    'seek': 0,\n",
              "    'start': 6.4,\n",
              "    'end': 7.6000000000000005,\n",
              "    'text': ' Hello, depression.',\n",
              "    'tokens': [18435, 11, 8862, 13],\n",
              "    'temperature': 0.0,\n",
              "    'avg_logprob': -0.25675727844238283,\n",
              "    'compression_ratio': 1.808724832214765,\n",
              "    'no_speech_prob': 0.08218304067850113},\n",
              "   {'id': 3,\n",
              "    'seek': 0,\n",
              "    'start': 7.6000000000000005,\n",
              "    'end': 9.92,\n",
              "    'text': \" Because when you're not doing anything you feel like shit.\",\n",
              "    'tokens': [4362, 618, 345, 821, 407, 1804, 1997, 345, 1254, 588, 7510, 13],\n",
              "    'temperature': 0.0,\n",
              "    'avg_logprob': -0.25675727844238283,\n",
              "    'compression_ratio': 1.808724832214765,\n",
              "    'no_speech_prob': 0.08218304067850113},\n",
              "   {'id': 4,\n",
              "    'seek': 0,\n",
              "    'start': 9.92,\n",
              "    'end': 12.0,\n",
              "    'text': \" And that's just a part of being a human being.\",\n",
              "    'tokens': [843, 326, 338, 655, 257, 636, 286, 852, 257, 1692, 852, 13],\n",
              "    'temperature': 0.0,\n",
              "    'avg_logprob': -0.25675727844238283,\n",
              "    'compression_ratio': 1.808724832214765,\n",
              "    'no_speech_prob': 0.08218304067850113},\n",
              "   {'id': 5,\n",
              "    'seek': 0,\n",
              "    'start': 12.0,\n",
              "    'end': 14.8,\n",
              "    'text': \" And we can pretend that we're something other than what we really are.\",\n",
              "    'tokens': [843,\n",
              "     356,\n",
              "     460,\n",
              "     16614,\n",
              "     326,\n",
              "     356,\n",
              "     821,\n",
              "     1223,\n",
              "     584,\n",
              "     621,\n",
              "     644,\n",
              "     356,\n",
              "     1107,\n",
              "     389,\n",
              "     13],\n",
              "    'temperature': 0.0,\n",
              "    'avg_logprob': -0.25675727844238283,\n",
              "    'compression_ratio': 1.808724832214765,\n",
              "    'no_speech_prob': 0.08218304067850113},\n",
              "   {'id': 6,\n",
              "    'seek': 0,\n",
              "    'start': 14.8,\n",
              "    'end': 18.8,\n",
              "    'text': \" And we can pretend, nah, me man, I'm just cool, just chilling, doing nothing.\",\n",
              "    'tokens': [843,\n",
              "     356,\n",
              "     460,\n",
              "     16614,\n",
              "     11,\n",
              "     299,\n",
              "     993,\n",
              "     11,\n",
              "     502,\n",
              "     582,\n",
              "     11,\n",
              "     314,\n",
              "     1101,\n",
              "     655,\n",
              "     3608,\n",
              "     11,\n",
              "     655,\n",
              "     28010,\n",
              "     11,\n",
              "     1804,\n",
              "     2147,\n",
              "     13],\n",
              "    'temperature': 0.0,\n",
              "    'avg_logprob': -0.25675727844238283,\n",
              "    'compression_ratio': 1.808724832214765,\n",
              "    'no_speech_prob': 0.08218304067850113},\n",
              "   {'id': 7,\n",
              "    'seek': 0,\n",
              "    'start': 18.8,\n",
              "    'end': 20.8,\n",
              "    'text': \" Bullshit. You're a fucking human.\",\n",
              "    'tokens': [8266, 16211, 13, 921, 821, 257, 9372, 1692, 13],\n",
              "    'temperature': 0.0,\n",
              "    'avg_logprob': -0.25675727844238283,\n",
              "    'compression_ratio': 1.808724832214765,\n",
              "    'no_speech_prob': 0.08218304067850113},\n",
              "   {'id': 8,\n",
              "    'seek': 0,\n",
              "    'start': 20.8,\n",
              "    'end': 26.48,\n",
              "    'text': \" You're a human being. You evolve from the fucking hundreds of thousands of years of hunters and gatherers\",\n",
              "    'tokens': [921,\n",
              "     821,\n",
              "     257,\n",
              "     1692,\n",
              "     852,\n",
              "     13,\n",
              "     921,\n",
              "     18101,\n",
              "     422,\n",
              "     262,\n",
              "     9372,\n",
              "     5179,\n",
              "     286,\n",
              "     4138,\n",
              "     286,\n",
              "     812,\n",
              "     286,\n",
              "     21490,\n",
              "     290,\n",
              "     308,\n",
              "     265,\n",
              "     1456,\n",
              "     3808],\n",
              "    'temperature': 0.0,\n",
              "    'avg_logprob': -0.25675727844238283,\n",
              "    'compression_ratio': 1.808724832214765,\n",
              "    'no_speech_prob': 0.08218304067850113},\n",
              "   {'id': 9,\n",
              "    'seek': 2648,\n",
              "    'start': 26.48,\n",
              "    'end': 31.44,\n",
              "    'text': ' and people who are struggling. Human reward systems are carved deeply into your DNA.',\n",
              "    'tokens': [290,\n",
              "     661,\n",
              "     508,\n",
              "     389,\n",
              "     9648,\n",
              "     13,\n",
              "     5524,\n",
              "     6721,\n",
              "     3341,\n",
              "     389,\n",
              "     23470,\n",
              "     7744,\n",
              "     656,\n",
              "     534,\n",
              "     7446,\n",
              "     13],\n",
              "    'temperature': 0.0,\n",
              "    'avg_logprob': -0.11549425627055922,\n",
              "    'compression_ratio': 1.5983935742971886,\n",
              "    'no_speech_prob': 9.901175701543252e-08},\n",
              "   {'id': 10,\n",
              "    'seek': 2648,\n",
              "    'start': 31.44,\n",
              "    'end': 36.56,\n",
              "    'text': \" And if you don't respect that, if you don't respect the mechanism of happiness and fulfillment\",\n",
              "    'tokens': [843,\n",
              "     611,\n",
              "     345,\n",
              "     836,\n",
              "     470,\n",
              "     2461,\n",
              "     326,\n",
              "     11,\n",
              "     611,\n",
              "     345,\n",
              "     836,\n",
              "     470,\n",
              "     2461,\n",
              "     262,\n",
              "     9030,\n",
              "     286,\n",
              "     12157,\n",
              "     290,\n",
              "     32402],\n",
              "    'temperature': 0.0,\n",
              "    'avg_logprob': -0.11549425627055922,\n",
              "    'compression_ratio': 1.5983935742971886,\n",
              "    'no_speech_prob': 9.901175701543252e-08},\n",
              "   {'id': 11,\n",
              "    'seek': 2648,\n",
              "    'start': 36.56,\n",
              "    'end': 40.08,\n",
              "    'text': ' and what you really need to do in order to feel satisfied in life,',\n",
              "    'tokens': [290,\n",
              "     644,\n",
              "     345,\n",
              "     1107,\n",
              "     761,\n",
              "     284,\n",
              "     466,\n",
              "     287,\n",
              "     1502,\n",
              "     284,\n",
              "     1254,\n",
              "     11378,\n",
              "     287,\n",
              "     1204,\n",
              "     11],\n",
              "    'temperature': 0.0,\n",
              "    'avg_logprob': -0.11549425627055922,\n",
              "    'compression_ratio': 1.5983935742971886,\n",
              "    'no_speech_prob': 9.901175701543252e-08},\n",
              "   {'id': 12,\n",
              "    'seek': 2648,\n",
              "    'start': 40.88,\n",
              "    'end': 48.0,\n",
              "    'text': ' comradery, love, family, friendship, struggle, testing yourself, learning,',\n",
              "    'tokens': [401,\n",
              "     6335,\n",
              "     1924,\n",
              "     11,\n",
              "     1842,\n",
              "     11,\n",
              "     1641,\n",
              "     11,\n",
              "     14738,\n",
              "     11,\n",
              "     6531,\n",
              "     11,\n",
              "     4856,\n",
              "     3511,\n",
              "     11,\n",
              "     4673,\n",
              "     11],\n",
              "    'temperature': 0.0,\n",
              "    'avg_logprob': -0.11549425627055922,\n",
              "    'compression_ratio': 1.5983935742971886,\n",
              "    'no_speech_prob': 9.901175701543252e-08},\n",
              "   {'id': 13,\n",
              "    'seek': 4800,\n",
              "    'start': 48.0,\n",
              "    'end': 58.0,\n",
              "    'text': \" all those things are imperative. They're all a giant part of being a person.\",\n",
              "    'tokens': [50363,\n",
              "     477,\n",
              "     883,\n",
              "     1243,\n",
              "     389,\n",
              "     23602,\n",
              "     13,\n",
              "     1119,\n",
              "     821,\n",
              "     477,\n",
              "     257,\n",
              "     6175,\n",
              "     636,\n",
              "     286,\n",
              "     852,\n",
              "     257,\n",
              "     1048,\n",
              "     13,\n",
              "     50863],\n",
              "    'temperature': 0.0,\n",
              "    'avg_logprob': -0.2100670099258423,\n",
              "    'compression_ratio': 1.027027027027027,\n",
              "    'no_speech_prob': 1.3861802017345326e-06}],\n",
              "  'language': 'en'}}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}